<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Bayesian inference of posterior probabilities · Findr.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://tmichoel.github.io/Findr.jl/posteriorprobs/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">Findr.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Introduction</a></li><li><a class="tocitem" href="../inference/">General inference algorithm</a></li><li><a class="tocitem" href="../realLLR/">Likelihood ratio tests</a></li><li><a class="tocitem" href="../randomLLR/">Null distributions of the LLRs</a></li><li class="is-active"><a class="tocitem" href>Bayesian inference of posterior probabilities</a><ul class="internal"><li><a class="tocitem" href="#Estimation"><span>Estimation</span></a></li><li><a class="tocitem" href="#Diagnostics"><span>Diagnostics</span></a></li><li><a class="tocitem" href="#Comparison"><span>Comparison</span></a></li></ul></li><li><a class="tocitem" href="../testLLR/">Tests to evaluate</a></li><li><a class="tocitem" href="../utils/">Utilities</a></li><li><a class="tocitem" href="../listfunctions/">List of functions</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Bayesian inference of posterior probabilities</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Bayesian inference of posterior probabilities</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/tmichoel/Findr.jl/blob/main/docs/src/posteriorprobs.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Bayesian-inference-of-posterior-probabilities"><a class="docs-heading-anchor" href="#Bayesian-inference-of-posterior-probabilities">Bayesian inference of posterior probabilities</a><a id="Bayesian-inference-of-posterior-probabilities-1"></a><a class="docs-heading-anchor-permalink" href="#Bayesian-inference-of-posterior-probabilities" title="Permalink"></a></h1><p>After obtaining the PDFs for the LLRs from real data and the null hypotheses, we can convert LLR values into posterior probabilities <span>$P({\mathcal H}_{\mathrm{alt}}\mid \mathrm{LLR})$</span>. We use a similar technique as in <sup class="footnote-reference"><a id="citeref-Chen2007" href="#footnote-Chen2007">[Chen2007]</a></sup>, which itself was based on a more general framework to estimate local FDRs in genome-wide studies <sup class="footnote-reference"><a id="citeref-Storey2003" href="#footnote-Storey2003">[Storey2003]</a></sup>. This framework assumes that the real distribution of a certain test statistic forms a mixture distribution of null and alternative hypotheses. After estimating the null distribution, either analytically or by simulation, it can be compared against the real distribution to determine the proportion of null hypotheses, and consequently the posterior probability that the alternative hypothesis is true at any value of the statistic.</p><p>To be precise, consider an arbitrary likelihood ratio test. The fundamental assumption is that in the limit <span>$\mathrm{LLR}\rightarrow 0^+$</span>, all test cases come from the null hypothesis (<span>${\mathcal H}_{\mathrm{null}}$</span>), whilst as <span>$\mathrm{LLR}$</span> increases, the proportion of alternative hypotheses (<span>${\mathcal H}_{\mathrm{alt}}$</span>) also grows. The mixture distribution of real LLR values is assumed to have a PDF as</p><p class="math-container">\[p(\mathrm{LLR}) = P({\mathcal H}_{\mathrm{null}}) p(\mathrm{LLR}\mid{\mathcal H}_{\mathrm{null}}) + P({\mathcal H}_{\mathrm{alt}})p(\mathrm{LLR}\mid{\mathcal H}_{\mathrm{alt}}).\]</p><p>The priors <span>$P({\mathcal H}_{\mathrm{null}})$</span> and <span>$P({\mathcal H}_{\mathrm{alt}})$</span> sum to unity and correspond to the proportions of null and alternative hypotheses in the mixture distribution. For any test <span>$i=0,\dots,5$</span>, Bayes&#39; theorem then yields its posterior probability as</p><p class="math-container">\[P({\mathcal H}_{\mathrm{alt}}^{(i)}\mid\mathrm{LLR}^{(i)}) = \frac{p(\mathrm{LLR}^{(i)}\mid{\mathcal H}_{\mathrm{alt}}^{(i)})}{p(\mathrm{LLR}^{(i)})}P({\mathcal H}_{\mathrm{alt}}^{(i)}).\]</p><p>Based on this, we can define the posterior probabilities of the selected hypotheses according to the table in the <a href="../inference/#General-inference-algorithm">General inference algorithm</a> section, i.e. the alternative for tests 0, 1, 2, 4, 5 and the null for test 3 as</p><p class="math-container">\[P_i\equiv \begin{cases}
    P({\mathcal H}_{\mathrm{alt}}^{(i)}\mid\mathrm{LLR}^{(i)}), &amp; i=0,1,2,4,5\\
    P({\mathcal H}_{\mathrm{null}}^{(i)}\mid\mathrm{LLR}^{(i)}),&amp;i=3
\end{cases}\]</p><p>Distributions can be estimated either separately for every <span>$(E,A)$</span> pair or by pooling across all <span>$(E,A)$</span> pairs. In practice, we test on the order of <span>$10^3$</span> to <span>$10^4$</span> candidate targets (&quot;<span>$B$</span>&quot;) for every <span>$(E,A)$</span> such that a separate conversion of LLR values to posterior probabilities is both feasible and recommended, as it accounts for different roles of every gene, especially hub genes, through different rates of alternative hypotheses.</p><p>Lastly, in a typical application of Findr, inputs of <span>$(E,A)$</span> pairs will have been pre-determined as the set of significant eQTL-gene pairs from a genome-wide eQTL associaton analysis. In such cases, we may naturally assume <span>$P_1=1$</span> for all considered pairs, and skip the primary test.</p><h2 id="Estimation"><a class="docs-heading-anchor" href="#Estimation">Estimation</a><a id="Estimation-1"></a><a class="docs-heading-anchor-permalink" href="#Estimation" title="Permalink"></a></h2><p>To estimate posterior probabilities, the original method<sup class="footnote-reference"><a id="citeref-Wang2017" href="#footnote-Wang2017">[Wang2017]</a></sup> approximated PDFs with histograms. This requires proper choices of histogram bin widths, <span>$P({\mathcal H}_{\mathrm{null}})$</span>, and techniques to ensure the conversion from LLR to posterior probability is monotonically increasing and smooth.</p><p><a href="https://github.com/tmichoel/Findr.jl">Findr.jl</a> uses an alternative, parametric approach, where the basic hypothesis is that the alternative distribution <span>$p(\mathrm{LLR}\mid{\mathcal H}_{\mathrm{alt}})$</span> for each test also follows an <a href="../randomLLR/#Findr.LBeta"><code>LBeta</code></a> distribution, that is, belongs to the same 2-parameter family of distributions as the null distributions. </p><p>Let us denote the random variable <span>$X=\mathrm{LLR}$</span> taking values <span>$x\geq 0$</span>, and <span>$\pi_0=P({\mathcal H}_{\mathrm{null}})$</span>. Our assumption is that</p><p class="math-container">\[X \sim \pi_0 \mathcal{D}(\alpha_0,\beta_0) + (1-\pi_0) \mathcal{D}(\alpha,\beta)\]</p><p>or</p><p class="math-container">\[p(x) = \pi_0 p(x \mid \alpha_0,\beta_0) + (1-\pi_0) p(x\mid \alpha,\beta)\]</p><p>where <span>$\mathcal{D}$</span> denotes an <a href="../randomLLR/#Findr.LBeta"><code>LBeta</code></a> distribution with its PDF  <span>$p(x\mid \alpha,\beta)$</span> defined in <a href="../randomLLR/#Null-distributions-of-the-log-likelihood-ratios">Null distributions of the log-likelihood ratios</a>. </p><p>Since the parameters <span>$\alpha_0$</span> and <span>$\beta_0$</span> of the null distribution are know exactly (see <a href="../randomLLR/#Null-distributions-of-the-log-likelihood-ratios">Null distributions of the log-likelihood ratios</a>), it reamins to estimate <span>$\pi_0$</span>, <span>$\alpha$</span>, and <span>$\beta$</span> from a set of random samples <span>$x_1, x_2,\dots,x_n$</span> of <span>$X$</span>.</p><h3 id="Estimating-\\pi_0"><a class="docs-heading-anchor" href="#Estimating-\\pi_0">Estimating <span>$\pi_0$</span></a><a id="Estimating-\\pi_0-1"></a><a class="docs-heading-anchor-permalink" href="#Estimating-\\pi_0" title="Permalink"></a></h3><p>To estimate <span>$\pi_0$</span> we convert the samples <span>$x_1, x_2,\dots,x_n$</span> to p values under the null hypothesis,</p><p class="math-container">\[p_i = P(X\geq x_i \mid {\mathcal H}_{\mathrm{null}}) = \int_{x_i}^\infty p(x \mid \alpha_0,\beta_0) = \mathrm{ccdf}(x_i\mid \alpha_0,\beta_0) \]</p><p>where <span>$\mathrm{ccdf}$</span> denotes the complementary CDF. The histogram of p-values would show the <a href="http://varianceexplained.org/statistics/interpreting-pvalue-histogram/">characteristic shape of a set of anti-conservative p-values</a> and <span>$\pi_0$</span> can be estimated by a <a href="http://varianceexplained.org/files/pi0boot.pdf">robust bootstrap procedure</a>:</p><article class="docstring"><header><a class="docstring-binding" id="Findr.pi0est" href="#Findr.pi0est"><code>Findr.pi0est</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">pi0est(pval)</code></pre><p>Estimate the proportion π0 of truly null features in a vector <code>pval</code> of p-values using a <a href="http://varianceexplained.org/files/pi0boot.pdf">bootstrap method</a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tmichoel/Findr.jl/blob/2236f4910c941193e33dea6185d9f5265b94bafd/src/posteriorprobs.jl#L292-L296">source</a></section></article><h3 id="Estimating-\\alpha-and-\\beta"><a class="docs-heading-anchor" href="#Estimating-\\alpha-and-\\beta">Estimating <span>$\alpha$</span> and <span>$\beta$</span></a><a id="Estimating-\\alpha-and-\\beta-1"></a><a class="docs-heading-anchor-permalink" href="#Estimating-\\alpha-and-\\beta" title="Permalink"></a></h3><p>To estimate <span>$\alpha$</span> and <span>$\beta$</span> we make use of the relation between the <a href="../randomLLR/#Findr.LBeta"><code>LBeta</code></a> and Beta distributions (see <a href="../randomLLR/#Null-distributions-of-the-log-likelihood-ratios">Null distributions of the log-likelihood ratios</a>). Define the random variable</p><p class="math-container">\[Y = 1 - e^{-2 X}\]</p><p>Since each component of the mixture distribution of <span>$X$</span> follows an <a href="../randomLLR/#Findr.LBeta"><code>LBeta</code></a> distribution, it follows that <span>$Y$</span> follows a mixture of Beta distributions,</p><p class="math-container">\[Y \sim \pi_0 B\Bigl(\frac{\alpha_0}{2},\frac{\beta_0}{2}\Bigr) + (1 - \pi_0) B\Bigl(\frac{\alpha}{2},\frac{\beta}{2}\Bigr)\]</p><p>This result can be derived as follows. The function <span>$g(x)= 1-e^{-2x}$</span> increases monotonically for <span>$x\geq 0$</span> and has the inverse <span>$g^{-1}(y)=-\frac{1}{2}\ln(1-y)$</span>. By the usual rules of transforming random variables:</p><p class="math-container">\[\begin{aligned}
    P(Y\leq y) &amp;= P(1 - e^{-2 X} \leq y) \\
    &amp;= P(X \leq g^{-1}(y))\\
    &amp;= \pi_0 P(X \leq g^{-1}(y) \mid \alpha_0,\beta_0) + (1-\pi_0) P(X \leq g^{-1}(y) \mid \alpha,\beta)\\
    &amp;= \pi_0 F_0(g^{-1}(y)) + (1-\pi_0) F_1(g^{-1}(y))\\
    &amp;= \pi_0 G_0(y) + (1-\pi_0) G_1(y)
\end{aligned}\]</p><p>where <span>$F_0$</span> and <span>$F_1$</span> are the CDFs of random variables with distributions <span>$\mathcal{D}(\alpha_0,\beta_0)$</span> and <span>$\mathcal{D}(\alpha,\beta)$</span>, respectively, and <span>$G_0$</span> and <span>$G_1$</span> are the CDFs of random variables with distributions <span>$B(\alpha_0/2,\beta_0/2)$</span> and <span>$B(\alpha/2,\beta/2)$</span>. The last step used the transformation between <a href="../randomLLR/#Findr.LBeta"><code>LBeta</code></a> and Beta distribution derived in  <a href="../randomLLR/#Null-distributions-of-the-log-likelihood-ratios">Null distributions of the log-likelihood ratios</a>.</p><p>The parameters of a Beta distribution relate to <a href="https://en.wikipedia.org/wiki/Beta_distribution#Higher_moments">its first and second moment</a> as follows: if <span>$Z\sim B(a,b)$</span>, then</p><p class="math-container">\[\begin{aligned}
    \mathbb{E}(Z) &amp;= \frac{a}{a+b} \equiv m_1(a,b)\\
    \mathbb{E}(Z^2) &amp;= \mathbb{E}(Z) \frac{a+1}{a+b+1} \equiv m_2(a,b)
\end{aligned}\]</p><p>Conversely, if first and second moments <span>$m_1$</span> and <span>$m_2$</span> are given, these equations can be inverted to give the parameters</p><p class="math-container">\[\begin{aligned}
    a &amp;= \frac{m_1(m_1-m_2)}{(m_2-m_1^2)}\\
    b &amp;= \frac{(1-m_1)(m_1-m_2)}{(m_2-m_1^2)}
\end{aligned}\]</p><p>Multiplying by two then gives the parameters of an <a href="../randomLLR/#Findr.LBeta"><code>LBeta</code></a> distribution given the moments of the corresponding Beta distribution:</p><article class="docstring"><header><a class="docstring-binding" id="Findr.fit_mom" href="#Findr.fit_mom"><code>Findr.fit_mom</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">fit_mom(LBeta, m1, m2)</code></pre><p>Fit an <code>LBeta</code> distribution to given first and second moments <code>m1</code> and <code>m2</code> of the corresponding Beta distribution.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tmichoel/Findr.jl/blob/2236f4910c941193e33dea6185d9f5265b94bafd/src/lbeta.jl#L95-L99">source</a></section></article><p>For the mixture distributed <span>$Y$</span>, we have</p><p class="math-container">\[\mathbb{E}(Y^k) = \pi_0 \mathbb{E}(Y^k \mid \alpha_0,\beta_0) + (1-\pi_0) \mathbb{E}(Y^k \mid \alpha,\beta)\]</p><p>and hence</p><p class="math-container">\[\begin{aligned}
    \mathbb{E}(Y) &amp;= \pi_0 m_1\bigl(\alpha_0/2,\beta_0/2\bigr) + (1-\pi_0) m_1\bigl(\alpha/2,\beta/2\bigr)\\
    \mathbb{E}(Y^2) &amp;= \pi_0 m_2\bigl(\alpha_0/2,\beta_0/2\bigr) + (1-\pi_0) m_2\bigl(\alpha/2,\beta/2\bigr)
\end{aligned}\]</p><p>or</p><p class="math-container">\[\begin{aligned}
    m_1\bigl(\alpha/2,\beta/2\bigr) &amp;= \frac{\mathbb{E}(Y) - \pi_0 m_1\bigl(\alpha_0/2,\beta_0/2\bigr)}{(1-\pi_0)}\\
    m_2\bigl(\alpha/2,\beta/2\bigr) &amp;= \frac{\mathbb{E}(Y^2) - \pi_0 m_2\bigl(\alpha_0/2,\beta_0/2\bigr)}{(1-\pi_0)}
\end{aligned}\]</p><p>Given samples <span>$x_1, x_2,\dots,x_n$</span> we transform them to</p><p class="math-container">\[y_i = 1 - e^{-2 x_i}\]</p><p>and replace <span>$\mathbb{E}(Y)$</span> and <span>$\mathbb{E}(Y^2)$</span> in these equations by their estimates <span>$\frac{1}{n}\sum_i y_i$</span> and <span>$\frac{1}{n}\sum_i y_i^2$</span>, respectively. Likewise we replace <span>$\pi_0$</span> by its estimate <span>$\hat{\pi}_0$</span> obtained as explained above (see <a href="#Findr.pi0est"><code>pi0est</code></a>). Since <span>$\alpha_0$</span> and <span>$\beta_0$</span> are known exactly, we obtain estimates <span>$\hat{m}_1$</span> and <span>$\hat{m}_2$</span> for the moments of a Beta distribution with parameters <span>$\alpha/2$</span> and <span>$\beta/2$</span>. Plugging these moment estimates in the <a href="#Findr.fit_mom"><code>fit_mom</code></a> function gives estimates <span>$\hat{\alpha}$</span> and <span>$\hat{\beta}$</span> for the corresponding <a href="../randomLLR/#Findr.LBeta"><code>LBeta</code></a>.</p><p>To make this estimated distribution a valid alternative distribution component of the LLRs mixture distribution, we need to ensure the validity of two edge cases:</p><ul><li>In the limit <span>$\mathrm{LLR}\to 0^+$</span>, all cases must come from the null distribution. This will be the case if <span>$\hat{\alpha} \geq \alpha_0$</span>, and if this is not the case, we set <span>$\hat{\alpha} = \alpha_0$</span>.</li><li>In the limit <span>$\mathrm{LLR}\to \infty$</span>, all cases must come from the alternative distribution. This will be the case if <span>$\hat{\beta} \leq \beta_0$</span>, and if this is not the case, we set <span>$\hat{\beta} = \beta_0$</span>.</li></ul><p>The entire procedure is implemented in the <code>fit_mixdist_mom</code> function:</p><article class="docstring"><header><a class="docstring-binding" id="Findr.fit_mixdist_mom" href="#Findr.fit_mixdist_mom"><code>Findr.fit_mixdist_mom</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">fit_mixdist_mom(llr,ns,ng=1,test=:corr)</code></pre><p>Fit a two-component mixture distribution of two LBeta distributions to a vector of log-likelihood ratios <code>llr</code> using a method-of-moments algorithm. The first component is the true null distribution for a given Findr <code>test</code> with sample size <code>ns</code> and number of genotype groups <code>ng</code>. The second component is the alternative distribution, assumed to follow an <a href="../randomLLR/#Findr.LBeta"><code>LBeta</code></a> distribution. The prior probability <code>pi0</code> of an observation belonging to the null component is fixed and determined by the <a href="#Findr.pi0est"><code>pi0est</code></a> function. Hence only the parameters of the alternative component need to be estimated.</p><p>The input variable <code>test</code> can take the values:</p><ul><li>:corr - <strong>correlation test</strong> (test 0)</li><li>:link - <strong>linkage test</strong> (test 1/2)</li><li>:med - <strong>mediation test</strong> (test 3)</li><li>:relev - <strong>relevance test</strong> (test 4)</li><li>:pleio - <strong>pleiotropy test</strong> (test 5)</li></ul><p>With two input arguments, the correlation test with <code>ns</code> samples is used. With three input arguments, or with four arguments and <code>test</code> equal to <code>:corr</code>, the correlation test with <code>ns</code> samples is used and the third argument is ignored.</p><p>See also <a href="#Findr.fit_mom"><code>fit_mom</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tmichoel/Findr.jl/blob/2236f4910c941193e33dea6185d9f5265b94bafd/src/posteriorprobs.jl#L101-L117">source</a></section></article><h2 id="Diagnostics"><a class="docs-heading-anchor" href="#Diagnostics">Diagnostics</a><a id="Diagnostics-1"></a><a class="docs-heading-anchor-permalink" href="#Diagnostics" title="Permalink"></a></h2><p>An important advantage of having a parametric solution for the observed LLR distributions, in the form of a <a href="https://juliastats.org/Distributions.jl/stable/mixture/">mixture model object</a>, is that its fit to the data can be evaluated easily. In this case, p-values for the real data under the real distribution must be uniformly distributed. Formally, if <span>$X$</span> is a continuous, univariate random variable with CDF <span>$F_X$</span>, then the transformed random variable</p>$<p>P = 1 - F_X(X) \sim U(0,1) $</p><p>where <span>$U(0,1)$</span> is the <a href="https://en.wikipedia.org/wiki/Continuous_uniform_distribution">uniform distribution</a> on the unit interval.</p><h2 id="Comparison"><a class="docs-heading-anchor" href="#Comparison">Comparison</a><a id="Comparison-1"></a><a class="docs-heading-anchor-permalink" href="#Comparison" title="Permalink"></a></h2><table><tr><th style="text-align: center">Old method</th><th style="text-align: center">New method</th></tr><tr><td style="text-align: center"><img src="../eg4.png" alt="Test"/></td><td style="text-align: center"><img src="../eg4_new.png" alt="Test"/></td></tr></table><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-Chen2007"><a class="tag is-link" href="#citeref-Chen2007">Chen2007</a>Chen L, Emmert-Streib F, Storey J. <a href="https://doi.org/10.1186/gb-2007-8-10-r219">Harnessing naturally randomized transcription to infer regulatory relationships among genes</a>. Genome Biol 8, R219 (2007).</li><li class="footnote" id="footnote-Storey2003"><a class="tag is-link" href="#citeref-Storey2003">Storey2003</a>Storey JD, Tibshirani R. <a href="https://doi.org/10.1073/pnas.1530509100">Statistical significance for genomewide studies</a>. Proceedings of the National Academy of Sciences. 2003;100(16):9440–9445.</li><li class="footnote" id="footnote-Wang2017"><a class="tag is-link" href="#citeref-Wang2017">Wang2017</a>Wang L, Michoel T (2017) <a href="https://doi.org/10.1371/journal.pcbi.1005703">Efficient and accurate causal inference with hidden confounders from genome-transcriptome variation data</a>. PLoS Comput Biol 13(8): e1005703.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../randomLLR/">« Null distributions of the LLRs</a><a class="docs-footer-nextpage" href="../testLLR/">Tests to evaluate »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Wednesday 14 June 2023 13:10">Wednesday 14 June 2023</span>. Using Julia version 1.9.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
